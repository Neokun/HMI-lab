{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# example, some code based on https://github.com/shihenw/convolutional-pose-machines-release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import skimage.io\n",
    "import skimage.transform\n",
    "import scipy.ndimage as ndimage\n",
    "import scipy.ndimage.filters as filters\n",
    "import cv2\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "import cpm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def detect_objects_heatmap(heatmap):\n",
    "  data = 256 * heatmap \n",
    "  data_max = filters.maximum_filter(data, 3, mode='reflect')\n",
    "  maxima = (data == data_max)\n",
    "  data_min = filters.minimum_filter(data, 3, mode='reflect')\n",
    "  diff = ((data_max - data_min) > 0.3)\n",
    "  maxima[diff == 0] = 0\n",
    "  labeled, num_objects = ndimage.label(maxima)\n",
    "  slices = ndimage.find_objects(labeled)\n",
    "  objects = np.zeros((num_objects, 2), dtype=np.int32)\n",
    "  for oid,(dy,dx) in enumerate(slices):\n",
    "    objects[oid,:] = [(dy.start + dy.stop - 1)/2, (dx.start + dx.stop - 1)/2]\n",
    "  return objects\n",
    "\n",
    "def gaussian_kernel(h, w, sigma_h, sigma_w):\n",
    "  yx = np.mgrid[-h//2:h//2,-w//2:w//2]**2\n",
    "  return np.exp(-yx[0,:,:] / sigma_h**2 - yx[1,:,:] / sigma_w**2)\n",
    "\n",
    "def prepare_input_posenet(image, objects, size_person, size, sigma=25, max_num_objects=16, border=400):\n",
    "  result = np.zeros((max_num_objects, size[0], size[1], 4))\n",
    "  padded_image = np.zeros((1,size_person[0]+border,size_person[1]+border,4))\n",
    "  padded_image[0,border//2:-border//2,border//2:-border//2,:3] = image\n",
    "  assert len(objects) < max_num_objects\n",
    "  for oid, (yc, xc) in enumerate(objects):\n",
    "    dh, dw = size[0]//2, size[1]//2\n",
    "    y0, x0, y1, x1 = np.array([yc-dh, xc-dw, yc+dh, xc+dw]) + border//2\n",
    "    result[oid,:,:,:4] = padded_image[:,y0:y1,x0:x1,:]\n",
    "    result[oid,:,:,3] = gaussian_kernel(size[0], size[1], sigma, sigma)\n",
    "  return np.split(result, [3], 3)\n",
    "\n",
    "def detect_parts_heatmaps(heatmaps, centers, size, num_parts=14):\n",
    "  parts = np.zeros((len(centers), num_parts, 2), dtype=np.int32)\n",
    "  for oid, (yc, xc) in enumerate(centers):\n",
    "    part_hmap = skimage.transform.resize(np.clip(heatmaps[oid], -1, 1), size, \n",
    "                                         mode='reflect') \n",
    "    for pid in range(num_parts):\n",
    "      y, x = np.unravel_index(np.argmax(part_hmap[:,:,pid]), size)\n",
    "      parts[oid,pid] = y+yc-size[0]//2,x+xc-size[1]//2\n",
    "  return parts\n",
    "\n",
    "LIMBS = np.array([1, 2, 3, 4, 4, 5, 6, 7, 7, 8, 9, 10, 10, 11, 12, 13, 13, 14]).reshape((-1,2))-1\n",
    "COLORS = [[0, 0, 255], [0, 170, 255], [0, 255, 170], [0, 255, 0], [170, 255, 0],\n",
    "          [255, 170, 0], [255, 0, 0], [255, 0, 170], [170, 0, 255]]\n",
    "\n",
    "def draw_limbs(image, parts):\n",
    "  for oid in range(parts.shape[0]):\n",
    "    for lid, (p0, p1) in enumerate(LIMBS):\n",
    "      y0, x0 = parts[oid][p0]\n",
    "      y1, x1 = parts[oid][p1]\n",
    "      cv2.line(image, (x0,y0), (x1,y1), COLORS[lid], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# path to pre-trained models\n",
    "# download here: https://drive.google.com/open?id=0Bw6m_66JSYLld0NESGQ4QUNEdFk\n",
    "model_path = '<enter-your-path-here>'\n",
    "person_net_path = os.path.join(model_path, 'person_net.ckpt') \n",
    "pose_net_path = os.path.join(model_path, 'pose_net.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.variable_scope('CPM'):\n",
    "  # input dims for the person network\n",
    "  PH, PW = 376, 656\n",
    "  image_in = tf.placeholder(tf.float32, [1,PH,PW,3])\n",
    "  heatmap_person = cpm.inference_person(image_in)\n",
    "  heatmap_person_large = tf.image.resize_images(heatmap_person, [PH, PW])\n",
    "  \n",
    "  # input dims for the pose network\n",
    "  N, H, W = 16, 376, 376\n",
    "  pose_image_in = tf.placeholder(tf.float32, [N,H,W,3])\n",
    "  pose_centermap_in = tf.placeholder(tf.float32, [N,H,W,1])\n",
    "  heatmap_pose = cpm.inference_pose(pose_image_in, pose_centermap_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf_config = tf.ConfigProto()\n",
    "tf_config.gpu_options.allow_growth = True\n",
    "tf_config.allow_soft_placement = True\n",
    "\n",
    "fname = 'nadal.png'\n",
    "\n",
    "image = skimage.io.imread(fname)\n",
    "image = skimage.transform.resize(image, [PH, PW], mode='constant', \n",
    "                                 preserve_range=True).astype(np.uint8)\n",
    "\n",
    "restorer = tf.train.Saver(tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, \n",
    "                                            'CPM/PersonNet'))\n",
    "\n",
    "with tf.Session(config=tf_config) as sess:\n",
    "  restorer.restore(sess, person_net_path)\n",
    "  b_image = image[np.newaxis] / 255.0 - 0.5\n",
    "  hmap_person = sess.run(heatmap_person_large, { image_in : b_image })\n",
    "  \n",
    "print('done detecting')  \n",
    "  \n",
    "# TODO: make this in tf as well?  \n",
    "hmap_person = np.squeeze(hmap_person)  \n",
    "centers = detect_objects_heatmap(hmap_person)  \n",
    "b_pose_image, b_pose_cmap = prepare_input_posenet(b_image[0], centers, [PH, PW], [H, W])  \n",
    "\n",
    "restorer = tf.train.Saver(tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, \n",
    "                                            'CPM/PoseNet'))\n",
    "\n",
    "with tf.Session(config=tf_config) as sess:\n",
    "  restorer.restore(sess, pose_net_path)\n",
    "  feed_dict = {\n",
    "    pose_image_in : b_pose_image,\n",
    "    pose_centermap_in : b_pose_cmap\n",
    "  }\n",
    "  _hmap_pose = sess.run(heatmap_pose, feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parts = detect_parts_heatmaps(_hmap_pose, centers, [H, W])\n",
    "draw_limbs(image, parts)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "toc": {
   "toc_cell": false,
   "toc_number_sections": true,
   "toc_threshold": 6,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
